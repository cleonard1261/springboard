{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Welcome to your first assignment. This exercise gives you a brief introduction to linear regression. The exercise is to be implemented in Python. Even if you've used Python before, this will help familiarize you with functions we'll need.  \n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
    "- Do not modify the (# GRADED FUNCTION [function name]) comment in some cells. Your work would not be graded if you change this. Each cell containing that comment should only contain one function.\n",
    "- After coding your function, run the cell right below it to check if your result is correct.\n",
    "\n",
    "**After this assignment you will:**\n",
    "- Be able to implement linear regression model using statsmodels, scikit-learn, and tensorflow\n",
    "- Work with simulated non-linear dataset\n",
    "- Compare model performance (quality of fit) of both models\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. You only need to write code between the ### START CODE HERE ### and ### END CODE HERE ### comments. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run Cell\" (denoted by a play symbol) in the upper bar of the notebook. \n",
    "\n",
    "We will often specify \"(≈ X lines of code)\" in the comments to tell you about how much code you need to write. It is just a rough estimate, so don't feel bad if your code is longer or shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "except: pass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as core_layers\n",
    "try:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    \"\"\"\n",
    "    Utility function to reset current tensorflow computation graph\n",
    "    and set the random seed \n",
    "    \"\"\"\n",
    "    # to make results reproducible across runs\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We use artificial data for the following two specifications of regression:\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "$ y(x) = a + b_1 \\cdot X_1 + b_2 \\cdot X_2 + b_3 \\cdot X_3 + \\sigma \\cdot \\varepsilon $ \n",
    "\n",
    "where $ \\varepsilon \\sim N(0, 1) $ is a Gaussian noise, and $ \\sigma $ is its volatility, \n",
    "with the following choice of parameters:\n",
    "\n",
    "$ a = 1.0 $\n",
    "\n",
    "$ b_1, b_2, b_3 = (0.5, 0.2, 0.1) $\n",
    "\n",
    "$ \\sigma = 0.1 $\n",
    "\n",
    "$ X_1, X_2, X_3 $ will be uniformally distributed in $ [-1,1] $\n",
    "\n",
    "### Non-Linear Regression\n",
    "\n",
    "$ y(x) = a + w_{00} \\cdot X_1 + w_{01} \\cdot X_2 + w_{02} \\cdot X_3 + + w_{10} \\cdot X_1^2 \n",
    "+ w_{11} \\cdot X_2^2 + w_{12} \\cdot X_3^2 +  \\sigma \\cdot \\varepsilon $ \n",
    "\n",
    "where\n",
    "\n",
    "$ w = [[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]]  $\n",
    "\n",
    "and the rest of parameters is as above, with the same values of $ X_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 3), (7500, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data(n_points=10000, n_features=3, use_nonlinear=True, \n",
    "                    noise_std=0.1, train_test_split = 4):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    n_points - number of data points to generate\n",
    "    n_features - a positive integer - number of features\n",
    "    use_nonlinear - if True, generate non-linear data\n",
    "    train_test_split - an integer - what portion of data to use for testing\n",
    "    \n",
    "    Return:\n",
    "    X_train, Y_train, X_test, Y_test, n_train, n_features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Linear data or non-linear data?\n",
    "    if use_nonlinear:\n",
    "        weights = np.array([[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]])\n",
    "    else:\n",
    "        weights = np.array([1.0, 0.5, 0.2])\n",
    "        \n",
    "    bias = np.ones(n_points).reshape((-1,1))\n",
    "    low = - np.ones((n_points,n_features),'float')\n",
    "    high = np.ones((n_points,n_features),'float')\n",
    "    \n",
    "    X = np.random.uniform(low=low, high=high)\n",
    "    noise = np.random.normal(size=(n_points, 1))\n",
    "    noise_std = 0.1\n",
    "    \n",
    "    if use_nonlinear:\n",
    "        Y = (weights[0,0] * bias + np.dot(X, weights[0, :]).reshape((-1,1)) + \n",
    "             np.dot(X*X, weights[1, :]).reshape([-1,1]) +\n",
    "             noise_std * noise)\n",
    "    else:\n",
    "        Y = (weights[0] * bias + np.dot(X, weights[:]).reshape((-1,1)) + \n",
    "             noise_std * noise)\n",
    "    \n",
    "    n_test = int(n_points/train_test_split)\n",
    "    n_train = n_points - n_test\n",
    "    \n",
    "    X_train = X[:n_train,:]\n",
    "    Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "    X_test = X[n_train:,:]\n",
    "    Y_test = Y[n_train:].reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, n_train, n_features\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, n_train, n_features = generate_data(use_nonlinear=False)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: numpy_lin_regress\n",
    "def numpy_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    numpy_lin_regress - Implements linear regression model using numpy module\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    # number of features\n",
    "    ndim = X_train.shape[1] \n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    X_train = np.c_[np.ones(X_train.shape[0]), X_train] \n",
    "    #print(np.linalg.lstsq(X_train,Y_train)[0])\n",
    "    \n",
    "    theta_numpy = np.linalg.lstsq(X_train,Y_train)[0]\n",
    "    #theta_numpy = np.array([0.] * (ndim + 1))  # replace this line with your calculation\n",
    "    ### END CODE HERE ###\n",
    "    return theta_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99898211,  1.00272359,  0.49716724,  0.20052866])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
    "theta_numpy.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# GRADED FUNCTION: sklearn_lin_regress\n",
    "def sklearn_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    ndim = X_train.shape[1] \n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    #theta_sklearn = np.array([0.] * (ndim + 1)) \n",
    "\n",
    "    theta_sklearn = np.c_[model.intercept_, model.coef_].T # replace this line with your calculation\n",
    "    ### END CODE HERE ###\n",
    "    return theta_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99898211,  1.00272359,  0.49716724,  0.20052866])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "theta_sklearn = sklearn_lin_regress(X_train, Y_train)\n",
    "theta_sklearn.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: tf_lin_regress\n",
    "def tf_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    ndim = X_train.shape[1] \n",
    "    ### START CODE HERE ### (≈ 7-8 lines of code)\n",
    "    #print(np.c_[np.ones(X_train.shape[0]),X_train])\n",
    "    X_train = tf.constant(np.c_[np.ones(X_train.shape[0]),X_train], dtype=tf.float32, name=\"X_train\")\n",
    "    Y_train = tf.constant(Y_train, dtype=tf.float32, name=\"Y_train\")\n",
    "    XT = tf.transpose(X_train)\n",
    "    theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X_train)), XT), Y_train)\n",
    "\n",
    "\n",
    "    #theta_value = np.array([0.] * (ndim + 1))  # replace this line with your calculation\n",
    "    with tf.Session() as sess:\n",
    "        theta_value = theta.eval()\n",
    "    ### END CODE HERE ###\n",
    "    return theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99898207,  1.00272393,  0.49716732,  0.20052864], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "theta_tf = tf_lin_regress(X_train, Y_train)\n",
    "theta_tf.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: run_normal_eq\n",
    "def run_normal_eq(X_train, Y_train, X_test, Y_test, learning_rate=0.05):\n",
    "    \"\"\"\n",
    "    Implements normal equation using tensorflow, trains the model using training data set\n",
    "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
    "    \n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    X_test  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    \n",
    "    Return a tuple of:\n",
    "        - np.array of size (k+1 by 1) of regression coefficients\n",
    "        - mean square error (MSE) of the test data set\n",
    "        - mean square error (MSE) of the training data set\n",
    "    \"\"\"\n",
    "    ndim = X_train.shape[1]\n",
    "    n = X_train.shape[0]\n",
    "    ### START CODE HERE ### (≈ 20 lines of code)\n",
    "    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "    X_tn = tf.constant(X_train, dtype=tf.float32, name=\"X_tn\")\n",
    "    X_ts = tf.constant(X_test, dtype=tf.float32, name=\"X_ts\")\n",
    "    Y_tn = tf.constant(Y_train, dtype=tf.float32, name=\"Y_tn\")\n",
    "    Y_ts = tf.constant(Y_test, dtype=tf.float32, name=\"Y_ts\")\n",
    "    XT = tf.transpose(X_tn)\n",
    "    \n",
    "    theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X_tn)),XT), Y_tn)\n",
    "    \n",
    "    lr_mse_tn = tf.reduce_mean(tf.square(tf.matmul(X_tn, theta) - Y_tn))\n",
    "    lr_mse_ts = tf.reduce_mean(tf.square(tf.matmul(X_ts, theta) - Y_ts))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        theta_value = theta.eval()\n",
    "        lr_mse_train = lr_mse_tn.eval()\n",
    "        lr_mse_test = lr_mse_ts.eval()\n",
    "    \n",
    "    #theta_value = np.array([0.] * (ndim + 1))\n",
    "    ### END CODE HERE ###\n",
    "    return theta_value, lr_mse_train, lr_mse_test\n",
    "\n",
    "### (DO NOT EDIT) ###\n",
    "theta_value, lr_mse_train, lr_mse_test = run_normal_eq(X_train, Y_train, X_test, Y_test)\n",
    "### (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99898207,  1.00272393,  0.49716732,  0.20052864], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "theta_value.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: run_mle\n",
    "def run_mle(X_train, Y_train, X_test, Y_test, learning_rate=0.05, num_iter=5000):\n",
    "    \"\"\"\n",
    "    Maximum likelihood Estimate (MLE)\n",
    "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
    "    \n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    X_test  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    \n",
    "    Return a tuple of:\n",
    "        - np.array of size (k+1 by 1) of regression coefficients\n",
    "        - mean square error (MSE) of the test data set\n",
    "        - mean square error (MSE) of the training data set\n",
    "    \"\"\"\n",
    "    # create an instance of the Linear Regression model class  \n",
    "    ndim = X_train.shape[1]\n",
    "    loss = 0.\n",
    "    std_model = 0.\n",
    "    n = X_train.shape[0]\n",
    "    ### START CODE HERE ### (≈ 20 lines of code)\n",
    "    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "    weights = np.dot(np.linalg.inv(np.dot(X_train.T,X_train)),np.dot(X_train.T,Y_train))\n",
    "    std_model = (1/n) * np.square(np.dot(X_train,weights) - Y_train)\n",
    "    loss = (1/n) * np.square(np.dot(X_test,weights) - Y_test)\n",
    "\n",
    "    \n",
    "    #weights = np.array([0.] * (ndim + 1))\n",
    "    ### END CODE HERE ###\n",
    "    return weights, loss, std_model\n",
    "\n",
    "weights, loss, std_model = run_mle(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99898211,  1.00272359,  0.49716724,  0.20052866])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "weights.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "coursera": {
   "course_slug": "guided-tour-machine-learning-finance",
   "graded_item_id": "dX8oQ",
   "launcher_item_id": "7Z9sN"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
